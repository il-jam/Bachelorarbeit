Hier meine Bachelorarbeit:

Entwicklung eines Interfaces für ein
Entscheidungsunterstützungssystem für die
Planung von Lebensmittelkontrollen

Kurzfassung

Die behördliche Lebensmittelüberwachung leistet einen wichtigen Teil zur Erhalt der öffentlichen Sicherheit. Durch zunehmende Anforderungen bei gleichzeitig steigendem Personalmangel ist in diesem Bereich der Bedarf für KI-basierte Unterstützungssysteme hoch. In dieser Arbeit wurde ein Interface für ein KI-basiertes Entscheidungsunterstützungssystem entworfen, das Lebensmittelkontrolleuren helfen soll, zu entscheiden, welche Betriebe priorisiert kontrolliert werden müssen. 
Das entwickelte System soll die Nutzer dabei unterstützen, die Berechnung der Risikobewertung und dahinterliegenden Prozesse nachvollziehen zu können. Zu diesem Zweck stellt das System Erklärungen und Begründungen in verschiedenen Formaten bereit, die die Entscheidungsfindung des KI-Systems und die beteiligten Prozesse transparent machen sollen.

Da die Entscheidung, welche Betriebe kontrolliert werden, einen Entscheidungsspielraum umfasst, darf sie nicht allein von einem KI-System getroffen werden. Darum ist es zentral, dass den Kontrolleuren die Gründe, warum ein Betrieb kontrolliert werden sollte, in einer Form präsentiert werden, die für sie nachvollziehbar ist. Daher ist eine nutzerzentrierte Gestaltung des Systems wichtig.

Für die Umsetzung dieses Ziels wurden zwei Bereiche betrachtet. Zum einen wurde der Forschungsbereich Explainable AI betrachtet, der sich damit beschäftigt, wie Nutzern die Ergebnisse und Prozesse eines KI-Systems verständlich erklärt werden können. Zum anderen wurde der Nutzungskontext der Lebensmittelüberwachung analysiert. Daraus wurden Anforderungen an das System abgeleitet. In einem iterativen Gestaltungsprozess wurde ein High-Fidelity-Prototyp entwickelt.
Um zu überprüfen, ob die Ziele der Arbeit erfüllt wurden, wurde in einer abschließenden Evaluation folgende Frage beantwortet: „Ist ein System, das auf Gestaltungsprinzipien für Explainable AI entwickelt wurde, nachvollziehbarer als ein System, das nicht auf solchen Prinzipien basiert?“. In einer abschließenden Evaluation wurde die Frage mit einem A/B-Test und weiteren Methoden überprüft. 

Die Auswertung der Daten lässt darauf schließen, dass die für die Evaluation gestellte Frage, ob ein auf XAI-basiertes System die Ergebnisse eines KI-Systems nachvollziehbarer macht als ein System ohne XAI-Feature, positiv beantwortet werden kann. Sowohl in Bezug auf die subjektive Wahrnehmung als auch objektive Maße (Bearbeitungsdauer) kann XAI eine Unterstützung sein. 

Schlüsselwörter: XAI, Explainable AI, Nachvollziehbarkeit, User Interface, Lebensmittelüberwachung 
